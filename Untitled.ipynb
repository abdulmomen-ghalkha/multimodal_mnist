{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498b6251-bd92-497b-8634-cc969cff6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1\n",
      "Finished epoch 2\n",
      "Finished epoch 3\n",
      "Finished epoch 4\n",
      "Finished epoch 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Define Image Encoder ---\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 6 * 6, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "# --- Define Audio Encoder ---\n",
    "class AudioEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, input_length):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self._calculate_output_dim(input_length), embedding_dim)\n",
    "        )\n",
    "\n",
    "    def _calculate_output_dim(self, input_length):\n",
    "        # This depends on your input audio length\n",
    "        length = input_length\n",
    "        length = (length - 3) // 2 + 1  # first conv\n",
    "        length = (length - 3) // 2 + 1  # second conv\n",
    "        return length * 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "# --- Cosine Similarity ---\n",
    "def cosine_similarity(a, b):\n",
    "    a_norm = F.normalize(a, dim=-1)\n",
    "    b_norm = F.normalize(b, dim=-1)\n",
    "    return a_norm @ b_norm.T\n",
    "\n",
    "\n",
    "# --- NT-Xent Loss ---\n",
    "def nt_xent_loss(img_embeds, aud_embeds, temperature=0.07):\n",
    "    batch_size = img_embeds.size(0)\n",
    "    sim_matrix = cosine_similarity(img_embeds, aud_embeds) / temperature\n",
    "    targets = torch.arange(batch_size, device=img_embeds.device)\n",
    "\n",
    "    loss_img2audio = F.cross_entropy(sim_matrix, targets)\n",
    "    loss_audio2img = F.cross_entropy(sim_matrix.T, targets)\n",
    "\n",
    "    return (loss_img2audio + loss_audio2img) / 2\n",
    "\n",
    "\n",
    "# --- Training Step with Alternating Updates ---\n",
    "def train_alternating(image_encoder, audio_encoder, dataloader, optimizer_img, optimizer_audio, device, temperature=0.07):\n",
    "    for batch in dataloader:\n",
    "        images, audios = batch\n",
    "        images, audios = images.to(device), audios.to(device)\n",
    "\n",
    "        # --- Step 1: Update Image Encoder ---\n",
    "        audio_encoder.eval()\n",
    "        image_encoder.train()\n",
    "\n",
    "        optimizer_img.zero_grad()\n",
    "        img_embeds = image_encoder(images)\n",
    "        with torch.no_grad():\n",
    "            aud_embeds = audio_encoder(audios)\n",
    "\n",
    "        loss_img = nt_xent_loss(img_embeds, aud_embeds, temperature)\n",
    "        loss_img.backward()\n",
    "        optimizer_img.step()\n",
    "\n",
    "        # --- Step 2: Update Audio Encoder ---\n",
    "        image_encoder.eval()\n",
    "        audio_encoder.train()\n",
    "\n",
    "        optimizer_audio.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            img_embeds = image_encoder(images)\n",
    "        aud_embeds = audio_encoder(audios)\n",
    "\n",
    "        loss_audio = nt_xent_loss(img_embeds, aud_embeds, temperature)\n",
    "        loss_audio.backward()\n",
    "        optimizer_audio.step()\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "embedding_dim = 128\n",
    "input_audio_length = 16000  # Example length after resampling\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "image_encoder = ImageEncoder(embedding_dim).to(device)\n",
    "audio_encoder = AudioEncoder(embedding_dim, input_audio_length).to(device)\n",
    "\n",
    "optimizer_img = torch.optim.Adam(image_encoder.parameters(), lr=1e-4)\n",
    "optimizer_audio = torch.optim.Adam(audio_encoder.parameters(), lr=1e-4)\n",
    "\n",
    "# --- Dummy DataLoader Example ---\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.randn(1, 28, 28)\n",
    "        audio = torch.randn(1, input_audio_length)\n",
    "        return img, audio\n",
    "\n",
    "dataloader = DataLoader(DummyDataset(100), batch_size=16, shuffle=True)\n",
    "\n",
    "# --- Run Training Epoch ---\n",
    "for epoch in range(5):\n",
    "    train_alternating(image_encoder, audio_encoder, dataloader, optimizer_img, optimizer_audio, device)\n",
    "    print(f\"Finished epoch {epoch + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6f20e-7f69-4c8a-a1a1-94d43292fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encoder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
